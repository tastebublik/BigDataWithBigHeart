{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VAZFAIpQlsnC",
    "outputId": "b4902be3-2fcf-44c0-8480-e89a4607335f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark==3.0.0\n",
      "  Downloading pyspark-3.0.0.tar.gz (204.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.7/204.7 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting py4j==0.10.9 (from pyspark==3.0.0)\n",
      "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.6/198.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyspark: filename=pyspark-3.0.0-py2.py3-none-any.whl size=205044159 sha256=017e4c9b5a99ff5fcd17f3f380987a0326d2d8973f03484aec6814e0fa235d3a\n",
      "  Stored in directory: /root/.cache/pip/wheels/b1/bb/8b/ca24d3f756f2ed967225b0871898869db676eb5846df5adc56\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "  Attempting uninstall: py4j\n",
      "    Found existing installation: py4j 0.10.9.7\n",
      "    Uninstalling py4j-0.10.9.7:\n",
      "      Successfully uninstalled py4j-0.10.9.7\n",
      "Successfully installed py4j-0.10.9 pyspark-3.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pyspark==3.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Dy0mP_ImZbS",
    "outputId": "ff81bb58-1684-4d34-9846-8921a2a55cd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopy in /usr/local/lib/python3.10/dist-packages (2.3.0)\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in /usr/local/lib/python3.10/dist-packages (from geopy) (2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BAXMIfSKmqHr"
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql as sql\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "id": "JBrCQdFYnHuU",
    "outputId": "8f0c527e-6b49-4ad5-d1aa-d68d1e131ce0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://a73b99b8f996:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=pyspark-shell>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    sc = SparkContext.getOrCreate()\n",
    "    sc.setLogLevel(\"ERROR\")\n",
    "except:\n",
    "    conf = SparkConf().setAppName(\"Lab1\").setMaster('local[1]')\n",
    "    sc = SparkContext(conf=conf)\n",
    "    sc.setLogLevel(\"ERROR\")\n",
    "spark = SparkSession(sc)\n",
    "\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MoJfScRynPHt",
    "outputId": "5f21af62-1e2f-403b-fe06-0568d8961cdc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: int, duration: int, start_date: timestamp, start_station_name: string, start_station_id: int, end_date: timestamp, end_station_name: string, end_station_id: int, bike_id: int, subscription_type: string, zip_code: string]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "with open(\"stations.csv\", \"wb\") as f:\n",
    "    request = requests.get(\"https://git.ai.ssau.ru/tk/big_data/raw/branch/bachelor/data/stations.csv\")\n",
    "    f.write(request.content)\n",
    "\n",
    "with open(\"trips.csv\", \"wb\") as f:\n",
    "    request = requests.get(\"https://git.ai.ssau.ru/tk/big_data/raw/branch/bachelor/data/trips.csv\")\n",
    "    f.write(request.content)\n",
    "\n",
    "tripData = spark.read\\\n",
    ".option(\"header\", True)\\\n",
    ".option(\"inferSchema\", True)\\\n",
    ".option(\"timestampFormat\", 'M/d/y H:m')\\\n",
    ".csv(\"trips.csv\")\n",
    "\n",
    "tripData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yfHazzM8mPLV",
    "outputId": "d4d79adc-8139-402d-f707-0951727126f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: int, name: string, lat: double, long: double, dock_count: int, city: string, installation_date: timestamp]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stationData = spark.read\\\n",
    ".option(\"header\", True)\\\n",
    ".option(\"inferSchema\", True)\\\n",
    ".option(\"timestampFormat\", 'M/d/y')\\\n",
    ".csv(\"stations.csv\")\n",
    "\n",
    "stationData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rZReBqA5mQtO",
    "outputId": "488b35d5-e2fe-4ad5-c0e2-5a15d64afc1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:\n",
      "+-------+--------+\n",
      "|bike_id|     dur|\n",
      "+-------+--------+\n",
      "|    535|18611693|\n",
      "+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "result = tripData.groupBy(\"bike_id\").agg(F.sum(\"duration\").alias(\"dur\")) \\\n",
    "                 .orderBy(F.desc(\"dur\")).limit(1)\n",
    "\n",
    "\n",
    "print(\"Result:\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vKIPVcrqmWFb",
    "outputId": "c811d3fc-7f8c-4a8a-a468-d64243e5cece"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наибольшее геодезическое расстояние между станциями 24 и 36: 9.669526104642657 км\n"
     ]
    }
   ],
   "source": [
    "from math import radians, cos, sin, asin, sqrt\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "stations_coordinates = stationData.select(\"id\", \"lat\", \"long\").withColumnRenamed(\"lat\", \"lat1\").withColumnRenamed(\"long\", \"long1\")\n",
    "stations_coordinates.createOrReplaceTempView(\"stations_coordinates\")\n",
    "\n",
    "station_combinations = spark.sql(\"\"\"\n",
    "    SELECT a.id as station1, b.id as station2, a.lat1, a.long1, b.lat1 as lat2, b.long1 as long2\n",
    "    FROM stations_coordinates a\n",
    "    CROSS JOIN stations_coordinates b\n",
    "    WHERE a.id < b.id\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    coord1 = (lat1, lon1)\n",
    "    coord2 = (lat2, lon2)\n",
    "    return geodesic(coord1, coord2).kilometers\n",
    "\n",
    "calculate_distance_udf = spark.udf.register(\"calculate_distance\", calculate_distance)\n",
    "\n",
    "result = station_combinations.withColumn(\"distance\", calculate_distance_udf(\"lat1\", \"long1\", \"lat2\", \"long2\"))\n",
    "\n",
    "max_distance = result.select(\"station1\", \"station2\", \"distance\").orderBy(col(\"distance\").desc()).first()\n",
    "\n",
    "print(f\"Наибольшее геодезическое расстояние между станциями {max_distance['station1']} и {max_distance['station2']}: {max_distance['distance']} км\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JwoI90SSm8DL",
    "outputId": "f23ee8ae-1fb6-4a2a-e789-b0ed09a8c4fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------------+\n",
      "|                name|    end_station_name|          distance|\n",
      "+--------------------+--------------------+------------------+\n",
      "|       2nd at Folsom|South Van Ness at...|2.3150845505323323|\n",
      "|South Van Ness at...|       2nd at Folsom|2.3150845505323323|\n",
      "+--------------------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import functions as F\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "max_duration_trip = tripData.orderBy(col(\"duration\").desc()).limit(1).select(\"start_station_name\", \"end_station_name\").first()\n",
    "\n",
    "filtered_joined_station = stationData \\\n",
    "    .filter((col(\"name\") == max_duration_trip.start_station_name) |\n",
    "            (col(\"name\") == max_duration_trip.end_station_name))\n",
    "\n",
    "result_3 = filtered_joined_station.crossJoin(\n",
    "    filtered_joined_station.select(col(\"name\").alias(\"end_station_name\"), col(\"lat\").alias(\"end_lat\"), col(\"long\").alias(\"end_long\"))\n",
    ") \\\n",
    ".withColumn(\"distance\", calculate_distance_udf(col(\"lat\"), col(\"long\"), col(\"end_lat\"), col(\"end_long\"))) \\\n",
    ".select(\"name\", \"end_station_name\", \"distance\") \\\n",
    ".filter((col(\"name\") != col(\"end_station_name\")) & (col(\"distance\") != 0))\n",
    "\n",
    "result_3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "USPe6cI9nC7U",
    "outputId": "5be455db-989c-4177-ff39-dd6eb7ac9872"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество велосипедов в системе: 700\n"
     ]
    }
   ],
   "source": [
    "bike_count = tripData.select(\"bike_id\").distinct().count()\n",
    "\n",
    "print(f\"Количество велосипедов в системе: {bike_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tdP9bU3BnDmM",
    "outputId": "3c95f1bf-1043-4a23-d79e-b23ee337d35d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат:\n",
      "+------+------------+\n",
      "|    id|sum_duration|\n",
      "+------+------------+\n",
      "|  6654|       17751|\n",
      "| 22097|       21686|\n",
      "| 22223|       15619|\n",
      "| 30654|       13479|\n",
      "| 34759|       17959|\n",
      "| 43688|       22504|\n",
      "| 88666|       21964|\n",
      "| 88674|       13726|\n",
      "|105536|       19854|\n",
      "|143153|       20649|\n",
      "|146988|       44084|\n",
      "|189310|       21785|\n",
      "|431881|       28377|\n",
      "|431018|       12301|\n",
      "|427387|       12612|\n",
      "|418759|       15526|\n",
      "|418461|       15103|\n",
      "|410754|       16743|\n",
      "|386707|       14313|\n",
      "|305619|       12412|\n",
      "+------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grouped_data = tripData.groupBy(\"id\").agg({\"duration\": \"sum\"}).withColumnRenamed(\"sum(duration)\", \"sum_duration\")\n",
    "\n",
    "filtered_data = grouped_data.filter(col(\"sum_duration\") > 10800)\n",
    "\n",
    "print(\"Результат:\")\n",
    "filtered_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "jpe7f9aSpWLW"
   },
   "outputs": [],
   "source": [
    "# Обязательно завершаем spark-сессию, чтобы не занимать ресурсы кластера\n",
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
